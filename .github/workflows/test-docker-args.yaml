name: docker-test-args

on:
  push:
    branches:
      - main
    paths-ignore:
      - '**.md'
      - 'website/**'
  pull_request:
    branches:
      - main
    paths-ignore:
      - '**.md'
      - 'website/**'

permissions: read-all

concurrency:
  group: ${{ github.workflow }}-${{ github.event.pull_request.number || github.ref }}
  cancel-in-progress: true

jobs:
  test:
    runs-on: ubuntu-latest
    timeout-minutes: 240
    strategy:
      fail-fast: false
      matrix:
        protocol:
          - oci
          - huggingface
          - https
    steps:
      - uses: jlumbroso/free-disk-space@54081f138730dfa15788a46383842cd2f914a1be # v1.3.1
        with:
          tool-cache: true
          android: true
          dotnet: true
          haskell: true
          large-packages: true
          docker-images: true
          swap-storage: true

      - name: Harden Runner
        uses: step-security/harden-runner@ec9f2d5744a09debf3a187a3f4f675c53b671911 # v2.13.0
        with:
          egress-policy: audit
          allowed-endpoints: >
            auth.docker.io:443
            *.huggingface.co:443
            cdn.dl.k8s.io:443
            dl.k8s.io:443
            download.docker.com:443
            gcr.io:443
            github.com:443
            huggingface.co:443
            *.githubusercontent.com:443
            production.cloudflare.docker.com:443
            proxy.golang.org:443
            registry-1.docker.io:443
            storage.googleapis.com:443
            *.blob.core.windows.net:443
            *.azureedge.net:443
            *.ubuntu.com:80
            developer.download.nvidia.com:443
            ghcr.io:443

      - uses: actions/checkout@11bd71901bbe5b1630ceea73d27597364c9af683 # v4.2.2

      # need containerd image store for testing local images
      - uses: crazy-max/ghaction-setup-docker@b60f85385d03ac8acfca6d9996982511d8620a19 # v4.3.0
        with:
          daemon-config: |
            {
              "debug": true,
              "features": {
                "containerd-snapshotter": true
              }
            }
      - uses: crazy-max/ghaction-github-runtime@3cb05d89e1f492524af3d41a1c98c83bc3025124 # v3.1.0

      - name: build aikit
        run: |
          docker buildx build . -t aikit:test \
            --load --provenance=false --progress plain \
            --cache-from=type=gha,scope=aikit-amd64 \
            --cache-to=type=gha,scope=aikit-amd64,mode=max

      - name: set url
        run: |
          if [ "${{ matrix.protocol }}" = "oci" ]; then
            echo "MODEL_URL=oci://registry.ollama.ai/library/llama3.2:1b" >> $GITHUB_ENV
            echo "MODEL_NAME=llama3.2" >> $GITHUB_ENV
          elif [ "${{ matrix.protocol }}" = "huggingface" ]; then
            echo "MODEL_URL=huggingface://MaziyarPanahi/Llama-3.2-1B-Instruct-GGUF/Llama-3.2-1B-Instruct.Q4_K_M.gguf" >> $GITHUB_ENV
            echo "MODEL_NAME=Llama-3.2-1B-Instruct.Q4_K_M.gguf" >> $GITHUB_ENV
          elif [ "${{ matrix.protocol }}" = "https" ]; then
            echo "MODEL_URL=https://huggingface.co/MaziyarPanahi/Llama-3.2-1B-Instruct-GGUF/resolve/main/Llama-3.2-1B-Instruct.Q4_K_M.gguf" >> $GITHUB_ENV
            echo "MODEL_NAME=Llama-3.2-1B-Instruct.Q4_K_M.gguf" >> $GITHUB_ENV
          fi

      - name: build test model
        run: |
          docker buildx build -t testmodel:test \
            --build-arg="model=$MODEL_URL" \
            --load --provenance=false --progress plain \
            --cache-from=type=gha,scope=testmodel-${{ matrix.protocol }} \
            --cache-to=type=gha,scope=testmodel-${{ matrix.protocol }},mode=max \
            "https://raw.githubusercontent.com/${REPO}/${SOURCE_BRANCH}/test/aikitfile-args.yaml"
        env:
          REPO: ${{ github.event.pull_request.head.repo.full_name || github.repository }}
          # github head ref is only set for pull_request targets
          # otherwise, get the github ref name to get the source branch
          SOURCE_BRANCH: ${{ github.head_ref || github.ref_name }}

      - name: list images
        run: docker images

      - name: run test model
        run: docker run --name testmodel -d -p 8080:8080 testmodel:test

      - name: run llama test
        run: |
          set -e
          result=$(curl --fail --retry 10 --retry-all-errors \
            http://127.0.0.1:8080/v1/chat/completions \
            -H "Content-Type: application/json" \
            -d "{\"model\": \"${MODEL_NAME}\", \"messages\": [{\"role\": \"user\", \"content\": \"explain kubernetes in a sentence\"}]}")
          echo $result

          choices=$(echo "$result" | jq '.choices')
          if [ -z "$choices" ]; then
            exit 1
          fi

      - name: save logs
        if: always()
        run: docker logs testmodel > /tmp/docker-${{ matrix.protocol }}.log

      - name: publish test artifacts
        if: always()
        uses: actions/upload-artifact@ea165f8d65b6e75b540449e92b4886f43607fa02 # v4.6.2
        with:
          name: test-${{ matrix.protocol }}
          path: |
            /tmp/*.log
